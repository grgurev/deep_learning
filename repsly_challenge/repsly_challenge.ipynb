{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Repsly trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data (this might take a minute or so)...done.\n"
     ]
    }
   ],
   "source": [
    "from repsly_data import RepslyData\n",
    "\n",
    "repsly_data = RepslyData()\n",
    "print('Reading data (this might take a minute or so)...', end='')\n",
    "repsly_data.read_data('data/trial_users_analysis.csv', mode='FC')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[20, 241]: [[ 153.    1.    1. ...,    0.    0.    0.]\n",
      " [ 224.    0.    0. ...,    0.    0.    0.]\n",
      " [  54.    0.    0. ...,    0.    0.    0.]\n",
      " ..., \n",
      " [ 185.    0.    0. ...,    0.    0.    0.]\n",
      " [  55.    0.    0. ...,    0.    0.    0.]\n",
      " [ 131.    0.    0. ...,    1.    5.    0.]]\n",
      "y: [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "read_batch = repsly_data.read_batch(batch_size=20)\n",
    "\n",
    "X, y = next(read_batch)\n",
    "print('X{}: {}'.format(list(X.shape), X))\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, each input vector `X` has `1+15*16=241` values, most of which are zeros. The first one is the trial start date as offset from `2016-01-01` and the rest is different usage parameters for the following `16` days. Data provided by batch read is randomly shuffled. Output values are stored in `y` and they represent if the user purchased the Repsly service after the trial or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a network with two fully connected hidden layers of size 250 and 50% dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repsly_nn import RepslyFC\n",
    "\n",
    "repsly_nn = RepslyFC()\n",
    "\n",
    "arch = [250, 250]\n",
    "arch_dict = {'keep_prob': 0.5}\n",
    "learning_rate = 0.001\n",
    "decay_steps=10\n",
    "decay_rate=0.99\n",
    "\n",
    "repsly_nn.create_net(arch, arch_dict, learning_rate, decay_steps, decay_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train it for some number of epochs. (NB. there is s bug with restoring checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs...\n",
      "Checkpoint directory is: /Users/davor/PycharmProjects/deep_learning/repsly_challenge/checkpoints/RepslyFC-[250,250]/keep_prob-0.5/lr-0.001/dr-0.99/ds-10\n",
      "Creating tf.train.Saver()...done\n",
      "self.checkpoint_path: checkpoints/RepslyFC-[250,250]/keep_prob-0.5/lr-0.001/dr-0.99/ds-10\n",
      "ckpt: None\n",
      "[00000/0.8 sec]   train/validation loss = 17.18806/9.96532\n",
      "[00010/1.9 sec]   train/validation loss = 14.93347/9.92426\n",
      "[00020/3.0 sec]   train/validation loss = 2.39778/2.31172\n",
      "[00030/3.8 sec]   train/validation loss = 3.73553/2.24757\n",
      "[00040/4.7 sec]   train/validation loss = 1.40663/2.33551\n",
      "[00050/5.7 sec]   train/validation loss = 1.50320/0.21643\n",
      "[00060/6.5 sec]   train/validation loss = 1.21213/2.59093\n",
      "[00070/7.5 sec]   train/validation loss = 1.80783/2.25574\n",
      "[00080/8.5 sec]   train/validation loss = 1.62885/1.17066\n",
      "[00090/9.3 sec]   train/validation loss = 3.21743/0.90493\n",
      "[00100/10.2 sec]   train/validation loss = 1.14871/1.04004\n",
      "[00110/11.2 sec]   train/validation loss = 0.51843/0.58444\n",
      "[00120/12.0 sec]   train/validation loss = 0.90816/0.53654\n",
      "[00130/12.9 sec]   train/validation loss = 0.93667/0.05713\n",
      "[00140/13.7 sec]   train/validation loss = 0.20114/0.65174\n",
      "[00150/14.7 sec]   train/validation loss = 0.47357/0.96657\n",
      "[00160/15.7 sec]   train/validation loss = 0.80797/0.43311\n",
      "[00170/16.5 sec]   train/validation loss = 1.42650/1.59427\n",
      "[00180/17.4 sec]   train/validation loss = 0.51344/0.49992\n",
      "[00190/18.4 sec]   train/validation loss = 0.36124/0.28722\n",
      "[00200/19.2 sec]   train/validation loss = 0.59826/0.41859\n",
      "[00210/20.1 sec]   train/validation loss = 0.77891/0.15444\n",
      "[00220/20.9 sec]   train/validation loss = 0.42681/0.36642\n",
      "[00230/21.8 sec]   train/validation loss = 0.47576/1.01412\n",
      "[00240/22.8 sec]   train/validation loss = 1.02216/0.30906\n",
      "[00250/23.7 sec]   train/validation loss = 0.94317/1.67970\n",
      "[00260/24.5 sec]   train/validation loss = 0.70545/0.41039\n",
      "[00270/25.5 sec]   train/validation loss = 0.25837/0.31398\n",
      "[00280/26.4 sec]   train/validation loss = 0.35756/0.40632\n",
      "[00290/27.3 sec]   train/validation loss = 0.31837/0.35396\n",
      "[00300/28.2 sec]   train/validation loss = 0.34281/0.39963\n",
      "[00310/29.0 sec]   train/validation loss = 0.51765/0.35049\n",
      "[00320/30.0 sec]   train/validation loss = 0.60914/0.34874\n",
      "[00330/30.9 sec]   train/validation loss = 0.56451/1.06639\n",
      "[00340/31.7 sec]   train/validation loss = 0.32951/0.37394\n",
      "[00350/32.7 sec]   train/validation loss = 0.33718/0.31960\n",
      "[00360/33.7 sec]   train/validation loss = 0.32211/0.57032\n",
      "[00370/34.5 sec]   train/validation loss = 0.39501/0.23863\n",
      "[00380/35.5 sec]   train/validation loss = 0.17863/0.35793\n",
      "[00390/36.4 sec]   train/validation loss = 0.34451/1.40775\n",
      "[00400/37.2 sec]   train/validation loss = 0.42558/0.31996\n",
      "[00410/38.2 sec]   train/validation loss = 0.59171/1.09892\n",
      "[00420/39.2 sec]   train/validation loss = 0.19292/0.39512\n",
      "[00430/40.0 sec]   train/validation loss = 0.21376/0.34554\n",
      "[00440/41.0 sec]   train/validation loss = 0.50818/0.44606\n",
      "[00450/42.0 sec]   train/validation loss = 0.18674/0.30097\n",
      "[00460/42.8 sec]   train/validation loss = 2.57100/0.39256\n",
      "[00470/43.7 sec]   train/validation loss = 0.29425/0.61863\n",
      "[00480/44.6 sec]   train/validation loss = 0.41068/0.32978\n",
      "[00490/45.5 sec]   train/validation loss = 0.43611/1.02985\n",
      "[00500/46.4 sec]   train/validation loss = 0.23165/0.35464\n",
      "[00510/47.3 sec]   train/validation loss = 0.23649/0.30294\n",
      "[00520/48.2 sec]   train/validation loss = 0.19915/0.43455\n",
      "[00530/49.2 sec]   train/validation loss = 0.31400/0.24487\n",
      "[00540/50.0 sec]   train/validation loss = 0.20307/0.33796\n",
      "[00550/51.0 sec]   train/validation loss = 0.30352/0.64761\n",
      "[00560/51.9 sec]   train/validation loss = 0.37126/0.30916\n",
      "[00570/52.8 sec]   train/validation loss = 0.38964/0.81848\n",
      "[00580/53.7 sec]   train/validation loss = 0.19064/0.34600\n",
      "[00590/54.7 sec]   train/validation loss = 0.22899/0.29790\n",
      "[00600/55.5 sec]   train/validation loss = 0.17832/0.36250\n",
      "[00610/56.5 sec]   train/validation loss = 0.27441/0.26490\n",
      "[00620/57.5 sec]   train/validation loss = 0.21385/0.36702\n",
      "[00630/58.3 sec]   train/validation loss = 0.31206/0.26736\n",
      "[00640/59.4 sec]   train/validation loss = 0.47105/0.32273\n",
      "[00650/60.2 sec]   train/validation loss = 0.47270/0.86047\n",
      "[00660/61.2 sec]   train/validation loss = 0.26672/0.33190\n",
      "[00670/62.2 sec]   train/validation loss = 0.26205/0.28360\n",
      "[00680/63.0 sec]   train/validation loss = 0.17954/0.33988\n",
      "[00690/64.0 sec]   train/validation loss = 0.17678/0.22363\n",
      "[00700/64.9 sec]   train/validation loss = 0.23229/0.34024\n",
      "[00710/65.7 sec]   train/validation loss = 0.36819/0.24808\n",
      "[00720/66.6 sec]   train/validation loss = 0.31021/0.31671\n",
      "[00730/67.6 sec]   train/validation loss = 0.35345/0.87113\n",
      "[00740/68.4 sec]   train/validation loss = 0.17641/0.31860\n",
      "[00750/69.4 sec]   train/validation loss = 0.22711/0.26551\n",
      "[00760/70.4 sec]   train/validation loss = 0.23582/0.31956\n",
      "[00770/71.2 sec]   train/validation loss = 0.21485/0.20696\n",
      "[00780/72.1 sec]   train/validation loss = 0.22868/0.33149\n",
      "[00790/73.1 sec]   train/validation loss = 0.30460/0.23386\n",
      "[00800/73.9 sec]   train/validation loss = 0.24799/0.31192\n",
      "[00810/74.9 sec]   train/validation loss = 0.37338/0.90825\n",
      "[00820/75.7 sec]   train/validation loss = 0.17287/0.32008\n",
      "[00830/76.6 sec]   train/validation loss = 0.28298/0.26939\n",
      "[00840/77.6 sec]   train/validation loss = 0.14023/0.31668\n",
      "[00850/78.4 sec]   train/validation loss = 0.20954/0.20306\n",
      "[00860/79.4 sec]   train/validation loss = 0.27335/0.31766\n",
      "[00870/80.4 sec]   train/validation loss = 0.28495/0.21134\n",
      "[00880/81.2 sec]   train/validation loss = 0.30391/0.30107\n",
      "[00890/82.2 sec]   train/validation loss = 0.42412/0.95039\n",
      "[00900/83.2 sec]   train/validation loss = 0.27730/0.32658\n",
      "[00910/84.0 sec]   train/validation loss = 0.24287/0.25548\n",
      "[00920/85.0 sec]   train/validation loss = 0.26450/0.28973\n",
      "[00930/85.9 sec]   train/validation loss = 0.25227/0.17939\n",
      "[00940/86.8 sec]   train/validation loss = 0.16962/0.30629\n",
      "[00950/87.8 sec]   train/validation loss = 0.39110/0.20314\n",
      "[00960/88.7 sec]   train/validation loss = 0.21110/0.29823\n",
      "[00970/89.5 sec]   train/validation loss = 0.29183/0.82606\n",
      "[00980/90.5 sec]   train/validation loss = 0.27134/0.34448\n",
      "[00990/91.3 sec]   train/validation loss = 0.17398/0.25075\n",
      "[01000/92.4 sec]   train/validation loss = 0.17507/0.27782\n",
      "[01010/93.4 sec]   train/validation loss = 0.25492/0.18585\n",
      "[01020/94.2 sec]   train/validation loss = 0.18930/0.30708\n",
      "[01030/95.2 sec]   train/validation loss = 0.27117/0.20515\n",
      "[01040/96.2 sec]   train/validation loss = 0.18369/0.29379\n",
      "[01050/97.0 sec]   train/validation loss = 0.35763/0.79560\n",
      "[01060/98.0 sec]   train/validation loss = 0.22728/0.30526\n",
      "[01070/99.0 sec]   train/validation loss = 0.22134/0.24345\n",
      "[01080/99.9 sec]   train/validation loss = 0.22991/0.28874\n",
      "[01090/100.9 sec]   train/validation loss = 0.18193/0.18677\n",
      "[01100/102.0 sec]   train/validation loss = 0.21288/0.30863\n",
      "[01110/103.1 sec]   train/validation loss = 0.30046/0.21305\n",
      "[01120/104.1 sec]   train/validation loss = 0.23868/0.29965\n",
      "[01130/105.0 sec]   train/validation loss = 0.38805/0.72303\n",
      "[01140/106.0 sec]   train/validation loss = 0.15739/0.30181\n",
      "[01150/107.0 sec]   train/validation loss = 0.16814/0.24693\n",
      "[01160/107.9 sec]   train/validation loss = 0.16908/0.30839\n",
      "[01170/108.8 sec]   train/validation loss = 0.19863/0.18444\n",
      "[01180/109.8 sec]   train/validation loss = 0.16171/0.30409\n",
      "[01190/110.6 sec]   train/validation loss = 0.30402/0.20819\n",
      "[01200/111.5 sec]   train/validation loss = 0.20717/0.29762\n",
      "[01210/112.6 sec]   train/validation loss = 0.30543/0.76065\n",
      "[01220/113.4 sec]   train/validation loss = 0.19405/0.30093\n",
      "[01230/114.4 sec]   train/validation loss = 0.24653/0.23885\n",
      "[01240/115.4 sec]   train/validation loss = 0.19846/0.28759\n",
      "[01250/116.1 sec]   train/validation loss = 0.16081/0.16124\n",
      "[01260/117.1 sec]   train/validation loss = 0.16036/0.29836\n",
      "[01270/118.0 sec]   train/validation loss = 0.35827/0.19025\n",
      "[01280/118.9 sec]   train/validation loss = 0.23214/0.29091\n",
      "[01290/119.8 sec]   train/validation loss = 0.35083/0.75848\n",
      "[01300/120.7 sec]   train/validation loss = 0.11168/0.29420\n",
      "[01310/121.6 sec]   train/validation loss = 0.21832/0.22708\n",
      "[01320/122.6 sec]   train/validation loss = 0.21306/0.28369\n",
      "[01330/123.4 sec]   train/validation loss = 0.21655/0.16496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01340/124.4 sec]   train/validation loss = 0.13067/0.29594\n",
      "[01350/125.4 sec]   train/validation loss = 0.30450/0.19573\n",
      "[01360/126.2 sec]   train/validation loss = 0.28386/0.29211\n",
      "[01370/127.2 sec]   train/validation loss = 0.30634/0.72007\n",
      "[01380/128.2 sec]   train/validation loss = 0.22192/0.28948\n",
      "[01390/129.0 sec]   train/validation loss = 0.19389/0.22231\n",
      "[01400/130.0 sec]   train/validation loss = 0.16087/0.28322\n",
      "[01410/131.0 sec]   train/validation loss = 0.19974/0.15466\n",
      "[01420/131.9 sec]   train/validation loss = 0.18367/0.28817\n",
      "[01430/132.8 sec]   train/validation loss = 0.29874/0.18214\n",
      "[01440/133.6 sec]   train/validation loss = 0.20993/0.28749\n",
      "[01450/134.6 sec]   train/validation loss = 0.29569/0.75456\n",
      "[01460/135.4 sec]   train/validation loss = 0.21969/0.28833\n",
      "[01470/136.3 sec]   train/validation loss = 0.23392/0.22658\n",
      "[01480/137.2 sec]   train/validation loss = 0.17178/0.26609\n",
      "[01490/138.2 sec]   train/validation loss = 0.17992/0.16214\n",
      "[01500/139.0 sec]   train/validation loss = 0.20815/0.28994\n",
      "[01510/140.0 sec]   train/validation loss = 0.26846/0.18986\n",
      "[01520/141.0 sec]   train/validation loss = 0.23442/0.29184\n",
      "[01530/141.8 sec]   train/validation loss = 0.40647/0.73117\n",
      "[01540/142.8 sec]   train/validation loss = 0.23989/0.28498\n",
      "[01550/143.8 sec]   train/validation loss = 0.20790/0.22101\n",
      "[01560/144.7 sec]   train/validation loss = 0.14559/0.26049\n",
      "[01570/145.7 sec]   train/validation loss = 0.18634/0.15052\n",
      "[01580/146.7 sec]   train/validation loss = 0.16366/0.28585\n",
      "[01590/147.5 sec]   train/validation loss = 0.34321/0.18380\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs_loops = 1\n",
    "epochs_at_once = 20\n",
    "skip_steps=10\n",
    "\n",
    "for i in range(epochs_loops):\n",
    "    print('Training for {} epochs...'.format(epochs_at_once))\n",
    "    repsly_nn.train(data=repsly_data, batch_size=batch_size, epochs=epochs_at_once, skip_steps=skip_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
